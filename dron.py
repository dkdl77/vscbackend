import os
import cv2
import numpy as np
import torch
import shutil
from sklearn.cluster import KMeans

# YOLOv5 ëª¨ë¸ ë¡œë“œ
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
model.eval()

# ì˜ìƒ ë¶ˆëŸ¬ì˜¤ê¸°
video_path = "c.mp4"
cap = cv2.VideoCapture(video_path)

# ì €ì¥ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
save_dir = "detected_people"
if os.path.exists(save_dir):
    shutil.rmtree(save_dir)
os.makedirs(save_dir)

# HSV ìƒ‰ìƒ ë²”ìœ„ (ì˜ˆ: ê²€ì •ìƒ‰ ì˜·)
target_upper_lower_hsv = {
    "upper": [
    (np.array([0, 100, 100]), np.array([10, 255, 255]))
],
    "lower": [
    (np.array([0, 100, 100]), np.array([10, 255, 255]))
]
}

# í”¼ë¶€ìƒ‰ ë²”ìœ„ (HSV)
skin_lower = np.array([0, 30, 60], dtype=np.uint8)
skin_upper = np.array([20, 150, 255], dtype=np.uint8)

# YOLO íƒì§€ ì„¤ì •
MIN_PERSON_HEIGHT = 100
CONF_THRESHOLD = 0.5

# í”¼ë¶€ìƒ‰ ì œê±° í›„ ìœ íš¨í•œ BGR í”½ì…€ ë°˜í™˜
def get_valid_pixels(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    skin_mask = cv2.inRange(hsv, skin_lower, skin_upper)
    mask_inv = cv2.bitwise_not(skin_mask)
    return image[mask_inv > 0]

# HSV ë²”ìœ„ì™€ ì¼ì¹˜ ì—¬ë¶€ íŒë‹¨
def is_color_in_range(image, hsv_ranges):
    valid_pixels = get_valid_pixels(image)
    if len(valid_pixels) == 0:
        return False
    hsv_pixels = cv2.cvtColor(valid_pixels.reshape(-1, 1, 3), cv2.COLOR_BGR2HSV).reshape(-1, 3)
    mask = np.zeros(len(hsv_pixels), dtype=bool)
    for lower, upper in hsv_ranges:
        in_range = np.all((hsv_pixels >= lower) & (hsv_pixels <= upper), axis=1)
        mask |= in_range
    ratio = np.sum(mask) / len(mask)
    return ratio > 0.4

# ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
def extract_dominant_colors(image, k=3):
    valid_pixels = get_valid_pixels(image)
    if len(valid_pixels) < k:
        return []
    kmeans = KMeans(n_clusters=k, n_init='auto')
    kmeans.fit(valid_pixels)
    centers = kmeans.cluster_centers_.astype(np.uint8)
    return centers

# í”„ë ˆì„ ì„¤ì •
frame_count = 0
frame_interval = 30  # 1ì´ˆ ê°„ê²© (30fps ê¸°ì¤€)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_count += 1
    if frame_count % frame_interval != 0:
        continue

    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = model(img_rgb)
    detections = results.xyxy[0].cpu().numpy()

    for i, (*box, conf, cls) in enumerate(detections):
        if int(cls) != 0 or conf < CONF_THRESHOLD:
            continue
        x1, y1, x2, y2 = map(int, box)
        if (y2 - y1) < MIN_PERSON_HEIGHT:
            continue

        # ì „ì²´ ë†’ì´
        full_height = y2 - y1
        margin_x = int((x2 - x1) * 0.1)
        margin_y = int(full_height * 0.1)

        # ìƒì²´: ìƒë‹¨ ë§ˆì§„ í¬í•¨, 45%
        upper_y1 = y1 + margin_y
        upper_y2 = y1 + int(full_height * 0.45)
        upper_img = frame[upper_y1:upper_y2, x1 + margin_x:x2 - margin_x]

        # í•˜ì²´: í•˜ë‹¨ ë§ˆì§„ í¬í•¨, 55%
        lower_y1 = y1 + int(full_height * 0.45)
        lower_y2 = y2 - margin_y
        lower_img = frame[lower_y1:lower_y2, x1 + margin_x:x2 - margin_x]

        is_upper_match = is_color_in_range(upper_img, target_upper_lower_hsv["upper"])
        is_lower_match = is_color_in_range(lower_img, target_upper_lower_hsv["lower"])

        if is_upper_match and is_lower_match:
            # ì›ë˜ ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ì „ì²´ ì´ë¯¸ì§€ ì €ì¥
            crop_img = frame[y1:y2, x1:x2]
            filename = f"{save_dir}/person_{frame_count}_{i}.jpg"
            cv2.imwrite(filename, crop_img)
            print(f"âœ… ì €ì¥ë¨: {filename}")

            # ì£¼ìš” ìƒ‰ìƒ ì¶œë ¥
            dominant_colors_upper = extract_dominant_colors(upper_img)
            dominant_colors_lower = extract_dominant_colors(lower_img)
            print(f"ğŸ‘• ìƒì˜ ì£¼ìš” ìƒ‰ìƒ: {dominant_colors_upper}")
            print(f"ğŸ‘– í•˜ì˜ ì£¼ìš” ìƒ‰ìƒ: {dominant_colors_lower}")

            # ë””ë²„ê¹…ìš© ë°•ìŠ¤ ì‹œê°í™”
            cv2.rectangle(frame, (x1 + margin_x, upper_y1), (x2 - margin_x, upper_y2), (0, 255, 0), 2)
            cv2.rectangle(frame, (x1 + margin_x, lower_y1), (x2 - margin_x, lower_y2), (255, 0, 0), 2)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)

    cv2.imshow("people", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()